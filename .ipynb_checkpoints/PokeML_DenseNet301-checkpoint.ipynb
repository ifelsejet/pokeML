{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ifelsejet/pokeML/blob/main/PokeML_DenseNet301.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8p7zXYe-Ydyw"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import random\n",
    "from tensorflow.keras import layers\n",
    "import sys\n",
    "from google.colab import files\n",
    "#import imghdr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqVzmA8iXiwH"
   },
   "source": [
    "Load Dataset From Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-kw8hmygXtcD"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/gdrive')\n",
    "#%cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MXCFw6epYNne",
    "outputId": "496267b0-6dce-423c-feda-30e4c18c9038"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHPKAcDbthWs",
    "outputId": "421a3bdc-d662-4b84-af53-5fa19f9e1990"
   },
   "outputs": [],
   "source": [
    "# return number of folders in dataset\n",
    "print(len(os.listdir('/content/drive/MyDrive/dataset')))\n",
    "# return number of images in a folder\n",
    "print(len(os.listdir('/content/drive/MyDrive/dataset/NidoranM')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "Jqu-pKQ1YatB",
    "outputId": "9ac25040-6a82-4c91-d8a3-e7df5dca6cd5"
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "with open('example.txt', 'w') as f:\n",
    "  f.write('some content')\n",
    "\n",
    "files.download('example.txt') # downloading files from Drive\n",
    "'''\n",
    "path = '/content/drive/MyDrive/dataset/NidoranM/'\n",
    "imgTest = ''\n",
    "for img in os.listdir(path):\n",
    "  #print(img)\n",
    "  imgTest = img\n",
    "imgSaveTest = mpimg.imread(path+\"/\"+imgTest)\n",
    "#print(imgSaveTest)\n",
    "fig = plt.figure()\n",
    "#plt.axis('off')\n",
    "plt.axis(\"off\")   # turns off axes\n",
    "#plt.axis(\"tight\")  # gets rid of white border\n",
    "#plt.axis(\"image\")  # square up the image instead of filling the \"figure\" space\n",
    "#fig.axes.get_xaxis().set_visible(False)\n",
    "#fig.axes.get_yaxis().set_visible(False)\n",
    "#plt.subplot(n,n,1)\n",
    "imgAlterTest = tf.image.flip_up_down(imgSaveTest)\n",
    "plt.imshow(imgAlterTest)\n",
    "#plt.savefig(path+\"/\"+ \"imgAlterTestFlipUpDowAHHN.png\",bbox_inches='tight',pad_inches = 0)\n",
    "fig = plt.figure()\n",
    "plt.axis(\"off\") \n",
    "flippedLR = tf.image.flip_left_right(imgSaveTest)\n",
    "plt.imshow(flippedLR)\n",
    "#plt.savefig(path+\"/\"+ \"imgAlterTestFlipLeftRight.png\",bbox_inches='tight',pad_inches = 0)\n",
    "#plt.savefig(path+\"/\"+ \"imgAlterTestFlipUpDowN.png\",bbox_inches='tight',pad_inches = 0)\n",
    "#files.download(path+imgTest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "_LuFTCUxz7PT",
    "outputId": "73657fa1-d4ab-4678-a804-0cfdbaee43c7"
   },
   "outputs": [],
   "source": [
    "# Augment Data for each pokemon that has under 60 images\n",
    "'''\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "                            layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "                            layers.experimental.preprocessing.RandomRotation((-0.2, 0.3))\n",
    "])\n",
    "path = '/content/drive/MyDrive/dataset/NidoranM'\n",
    "#image, label = next(iter(os.listdir('/content/drive/MyDrive/dataset/NidoranM'))\n",
    "n = 9\n",
    "cnt = 0\n",
    "#TODO: Iterate over all labels, then create 250x250 plt figures\n",
    "#of all pokemons, then save it locally (Pokemon_AugmentType_CNT?.png)\n",
    "\n",
    "for img in os.listdir(path):\n",
    "  #print(img) \n",
    "  cnt += 1\n",
    "  image = mpimg.imread(path+\"/\"+img)\n",
    "  #print(image)\n",
    "  fig = plt.figure()\n",
    "  plt.subplot(n,n,1)\n",
    "  plt.title('Original image')\n",
    "  plt.imshow(image)\n",
    "\n",
    "  plt.subplot(n,n,2)\n",
    "  plt.title('Augmented image  (Left -> Right)')\n",
    "  #plt.imshow(augmented)\n",
    "  flippedLR = tf.image.flip_left_right(image)\n",
    "  plt.imshow(flippedLR)\n",
    "  plt.subplot(n,n,3)\n",
    "  plt.title('Augmented image  (Up -> Down)')\n",
    "  #plt.imshow(augmented)\n",
    "  flippedUD = tf.image.flip_up_down(image)\n",
    "  plt.imshow(flippedUD)\n",
    "  plt.subplot(n,n,4)\n",
    "  plt.title('Augmented image  (Rotate90)')\n",
    "  #plt.imshow(augmented)\n",
    "  rotated = tf.image.rot90(image)\n",
    "  plt.imshow(rotated)\n",
    "  plt.subplot(n,n,5)\n",
    "  plt.title('Augmented image  (Rotate180)')\n",
    "  #plt.imshow(augmented)\n",
    "  rotated180 = tf.image.rot90(tf.image.rot90(image))\n",
    "  plt.imshow(rotated180)\n",
    "  plt.subplot(n,n,6)\n",
    "  plt.title('Augmented image  (Rotate270)')\n",
    "  #plt.imshow(augmented)\n",
    "  rotated270 = tf.image.rot90(tf.image.rot90(tf.image.rot90(image)))\n",
    "  plt.imshow(rotated270)\n",
    "  plt.subplot(n,n,7)\n",
    "  plt.title('Augmented image  (Rotate90 + Flip U/D)')\n",
    "  #plt.imshow(augmented)\n",
    "  rotateflipUD = tf.image.rot90(tf.image.flip_up_down(image))\n",
    "  plt.imshow(rotateflipUD)\n",
    "  plt.subplot(n,n,8)\n",
    "  plt.title('Augmented image  (Rotate90 + Flip L/R)')\n",
    "  #plt.imshow(augmented)\n",
    "  rotateflip90LR = tf.image.rot90(tf.image.flip_left_right(image))\n",
    "  plt.imshow(rotateflip90LR)\n",
    "  plt.subplot(n,n,9)\n",
    "  plt.title('Augmented image  (Flip L/R + U/D)')\n",
    "  #plt.imshow(augmented)\n",
    "  flipLRUD = tf.image.flip_left_right(tf.image.flip_up_down(image))\n",
    "  plt.imshow(flipLRUD)\n",
    "  #plt.savefig(\"Test Save \" + str(cnt) + \".png\")\n",
    "  #visualize(image, flipped)\n",
    "  #plt.figure(figsize = (10,10))\n",
    "  #print(image)\n",
    "  #plt.imshow(image)\n",
    "  #plt.show()\n",
    "#exampleImg = cv2.imread('/content/drive/MyDrive/dataset/NidoranM/nnnn.png')\n",
    "#plt.imshow(exampleImg)\n",
    "#plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyN1xwg0b3fG"
   },
   "source": [
    "Get labels (folder names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCY-eLzTwbjQ",
    "outputId": "2c840006-8f8f-4952-c132-54fda8170e77"
   },
   "outputs": [],
   "source": [
    "labels = os.listdir('/content/drive/MyDrive/dataset')\n",
    "print(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIS7jwW5gXBJ"
   },
   "outputs": [],
   "source": [
    "# iterate over all labels\n",
    "# for each label, iterate over all images\n",
    "# iterate all images in directory, then upload to google drive\n",
    "\n",
    "\n",
    "# DONT RUN YET\n",
    "upload = False # don't want to update images every time we run the notebook, set to False\n",
    "dir = '/content/drive/MyDrive/dataset/'\n",
    "labels = os.listdir(dir)\n",
    "cnt = 0\n",
    "if upload:\n",
    "  for label in labels:\n",
    "    path = dir+str(label)\n",
    "    if len(os.listdir(path)) < 200: #only augment if less than 200 images total \n",
    "        for img in os.listdir(path):\n",
    "          cnt +=1\n",
    "          image = mpimg.imread(path+\"/\"+img)\n",
    "          #print(imghdr.what(image)\n",
    "          sample_str = str(path)+\"/\"+img\n",
    "          last_chars = sample_str[-4:]\n",
    "         # print(last_chars)\n",
    "          if(len(image.shape)== 3 and (last_chars != \".svg\") and len(os.listdir(path)) < 200):\n",
    "            fig = plt.figure()\n",
    "            plt.axis(\"off\")\n",
    "            print(\"Curr image: \" + path+\"/\"+str(img))\n",
    "            #print(\"Image shape\", len(image.shape))\n",
    "            imgAlterTest = tf.image.flip_up_down(image)\n",
    "            plt.imshow(imgAlterTest)\n",
    "            plt.savefig(path+\"/\"+ str(label)+str(cnt)+\"UD.png\",bbox_inches='tight',pad_inches = 0)\n",
    "            fig = plt.figure()\n",
    "            plt.axis(\"off\") \n",
    "            flippedLR = tf.image.flip_left_right(image)\n",
    "            plt.imshow(flippedLR)\n",
    "            plt.savefig(path+\"/\"+ str(label)+str(cnt)+\"LR.png\",bbox_inches='tight',pad_inches = 0)\n",
    "            fig = plt.figure()\n",
    "            plt.axis(\"off\")\n",
    "            rotated = tf.image.rot90(image)\n",
    "            plt.imshow(rotated)\n",
    "            plt.savefig(path+\"/\"+ str(label)+str(cnt)+\"rot90.png\",bbox_inches='tight',pad_inches = 0)\n",
    "            fig = plt.figure()\n",
    "            plt.axis(\"off\") \n",
    "            rotated180 = tf.image.rot90(tf.image.rot90(image))\n",
    "            plt.imshow(rotated180)\n",
    "            plt.savefig(path+\"/\"+ str(label)+str(cnt)+\"rot180.png\",bbox_inches='tight',pad_inches = 0)\n",
    "            fig = plt.figure()\n",
    "            plt.axis(\"off\") \n",
    "            rotated270 = tf.image.rot90(tf.image.rot90(tf.image.rot90(image)))\n",
    "            plt.imshow(rotated270)\n",
    "            plt.savefig(path+\"/\"+ str(label)+str(cnt)+\"rot270.png\",bbox_inches='tight',pad_inches = 0)\n",
    "            fig = plt.figure()\n",
    "            plt.axis(\"off\") \n",
    "            rotateflipUD = tf.image.rot90(tf.image.flip_up_down(image))\n",
    "            plt.imshow(rotateflipUD)\n",
    "            plt.savefig(path+\"/\"+ str(label)+str(cnt)+\"rotUD.png\",bbox_inches='tight',pad_inches = 0)\n",
    "            fig = plt.figure()\n",
    "            plt.axis(\"off\") \n",
    "            rotateflip90LR = tf.image.rot90(tf.image.flip_left_right(image))\n",
    "            plt.imshow(rotateflip90LR)\n",
    "            plt.savefig(path+\"/\"+ str(label)+str(cnt)+\"rotLR.png\",bbox_inches='tight',pad_inches = 0)\n",
    "            fig = plt.figure()\n",
    "            plt.axis(\"off\") \n",
    "            flipLRUD = tf.image.flip_left_right(tf.image.flip_up_down(image))\n",
    "            plt.imshow(flipLRUD)\n",
    "            plt.savefig(path+\"/\"+ str(label)+str(cnt)+\"LRUD.png\",bbox_inches='tight',pad_inches = 0)\n",
    "  print(\"Finished augmenting: \" + str(label))\n",
    "      #print(str(label)+ str(cnt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "HBltRe9Jwk70",
    "outputId": "f7e97078-ff20-458f-8470-d140841d210c"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Check to see if each pokemon (label) has equal size\n",
    "check = 0 # should be 150 post for loop\n",
    "lowest = 1000000000\n",
    "highest = 0\n",
    "avg = 0\n",
    "for label in labels:\n",
    "  dir = '/content/drive/MyDrive/dataset/'\n",
    "  dir+= str(label)\n",
    "  #print(dir)\n",
    "  count = len(os.listdir(dir))\n",
    "  print(\"Pokemon & Count: \", label, count)\n",
    "  check += 1\n",
    "  avg += count\n",
    "  lowest = min(lowest, count)\n",
    "  highest = max(highest, count)\n",
    "#print(check) # check if collected all 150 pokemon (actually 149?)\n",
    "print(\"Lowest, Highest, Avg # of images\", lowest, highest, round(avg/count))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wb4tnIF6w7iU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7h-0qR4u8yt",
    "outputId": "6fda73f2-a5d4-4bb6-99bc-0868ae3ed0e0"
   },
   "outputs": [],
   "source": [
    "# Resize images to 150x150 (or play around w it, smaller images = less calculations) \n",
    "# Normalize pixel values\n",
    "# Convert images to NumPy arrays (64x64)\n",
    "# Credit to that Kaggle one\n",
    "dir = '/content/drive/MyDrive/dataset/'\n",
    "stored = {}\n",
    "def input_target_split(train_dir,labels):\n",
    "    dataset = []\n",
    "    count = 0\n",
    "    for label in labels:\n",
    "        folder = os.path.join(train_dir,label)\n",
    "        for image in os.listdir(folder):\n",
    "            \n",
    "#             print(os.path.join(folder,image))\n",
    "            try:\n",
    "                img=load_img(os.path.join(folder,image), target_size=(150,150))\n",
    "                img=img_to_array(img)\n",
    "                img=img/255.0\n",
    "                dataset.append((img,count))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        print(f'\\rCompleted: {label}',end='')\n",
    "        stored[label] = count\n",
    "        count+=1\n",
    "    random.shuffle(dataset)\n",
    "    X, y = zip(*dataset)\n",
    "    \n",
    "    return np.array(X),np.array(y)\n",
    "X, y = input_target_split(dir,labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wmfq7dO_px0v"
   },
   "outputs": [],
   "source": [
    "# Shuffle only training dataset, then split into train, val and test (arrays)\n",
    "# training is about 150 images per pokemon (assuming 200 images each, choosing a specific CNN arch) [aim for 70% acc on training]\n",
    "# validation is about 40 images per pokemon (testing hyperparameters, increasing acc from training)\n",
    "# test is about 10 images per pokemon\n",
    "\n",
    "plt.figure(figsize = (15 , 9))\n",
    "n = 0\n",
    "for i in range(15):\n",
    "    n+=1\n",
    "    plt.subplot(5 , 5, n)\n",
    "    plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)\n",
    "    plt.imshow(X[i])\n",
    "    plt.title(f'Label: {labels[y[i]]}')\n",
    "\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZeyz5P-vsEe"
   },
   "outputs": [],
   "source": [
    "# show image grid & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lybn6y2nv3_0"
   },
   "outputs": [],
   "source": [
    "# train model on training dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.22, random_state=42)\n",
    "print(np.unique(y_train,return_counts=True),np.unique(y_test,return_counts=True))\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             rotation_range=20,\n",
    "                             zoom_range=0.2,\n",
    "                             width_shift_range = 0.2,\n",
    "                             height_shift_range = 0.2,\n",
    "                             shear_range=0.1,\n",
    "                             fill_mode=\"nearest\")\n",
    "\n",
    "testgen = ImageDataGenerator()\n",
    "\n",
    "datagen.fit(X_train)\n",
    "testgen.fit(X_test)\n",
    "\n",
    "y_train = np.eye(nb)[y_train]\n",
    "y_test = np.eye(nb)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gc314VOFxUPR"
   },
   "outputs": [],
   "source": [
    "# tune hyperparameters w/ validation dataset \n",
    "# (play with parameters passed and see which give the best results)\n",
    "\n",
    "img_size = 150\n",
    "base_model = DenseNet201(include_top = False,\n",
    "                         weights = 'imagenet',\n",
    "                         input_shape = (img_size,img_size,3))\n",
    "\n",
    "for layer in base_model.layers[:675]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in base_model.layers[675:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXksI_Kpzdn-"
   },
   "outputs": [],
   "source": [
    "# once ideal hyperparamters are found, pass in the testing dataset to model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(nb, activation=tf.nn.softmax))\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.001), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath= \"model_pokemon.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_weights_only=False)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',min_delta = 0, patience = 5, verbose = 1, restore_best_weights=True)\n",
    "\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.2, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "callbacks_list = [\n",
    "        checkpoint,\n",
    "        early_stopping,\n",
    "        learning_rate_reduction\n",
    "    ]\n",
    "\n",
    "hist = model.fit_generator(datagen.flow(X_train,y_train,batch_size=32),\n",
    "                                        validation_data=testgen.flow(X_test,y_test,batch_size=32),\n",
    "                                        epochs=50,\n",
    "                                        callbacks=callbacks_list)\n",
    "y_pred = model.predict(X_test)\n",
    "pred = np.argmax(y_pred,axis=1)\n",
    "print(pred)\n",
    "\n",
    "ground = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1Q-ASEzv7WC"
   },
   "outputs": [],
   "source": [
    "# run classification report (skmetrics/tensorflow)\n",
    "print(classification_report(ground,pred,target_names = labels))\n",
    "\n",
    "y_pred\n",
    "\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "y_pred\n",
    "\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRCIp6EWwHQK"
   },
   "outputs": [],
   "source": [
    "# show wrongly classified images\n",
    "\n",
    "plt.figure(figsize = (15 , 9))\n",
    "n = 0\n",
    "for i in range(len(X_test)):\n",
    "    if y_pred[i] != y_true[i]:\n",
    "        n+=1\n",
    "        if n <= 25:\n",
    "            plt.subplot(5 , 5, n)\n",
    "            plt.subplots_adjust(hspace = 0.8 , wspace = 0.3)\n",
    "            plt.imshow(X_test[i])\n",
    "            plt.title(f'Actual: {labels[y_true[i]]}\\nPredicted: {labels[y_pred[i]]}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
